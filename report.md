# AI와 테스트를 활용한 안정적인 기능 개발 리포트

## 사용하는 도구를 선택한 이유가 있을까요? 각 도구의 특징에 대해 조사해본적이 있나요?

이번 프로젝트에서는 Claude Code를 사용했습니다.

Claude Code는 Sub-Agent 구조를 통해 역할을 분리하고, 컨텍스트를 독립적으로 가져갈 수 있는 특징이 있습니다. 예를 들어 RED, GREEN, REFACTOR 같은 TDD 단계별로 다른 에이전트를 설정할 수 있어, 복잡한 작업도 명확한 책임 분리 하에 관리할 수 있었습니다.

## 테스트를 기반으로 하는 AI를 통한 기능 개발과 없을 때의 기능개발은 차이가 있었나요?

테스트가 있을 때는 코드가 제대로 작동하는지 바로바로 확인할 수 있어서 훨씬 마음이 편했습니다. 작은 수정이나 리팩터링을 해도 어디서 문제가 생겼는지 금방 알 수 있었고, 결과적으로 개발 속도도 안정적으로 유지됐어요. 반대로 테스트가 없을 때는 코드가 돌아가긴 해도 늘 불안했습니다. 수정할 때마다 “이게 다른 부분에 영향 주지 않을까?” 하는 생각이 들었고, 실제로 예기치 못한 버그가 자주 생겼습니다. 테스트가 있으면 내가 짠 코드에 근거 있는 확신이 생기지만, 없을 때는 늘 감으로 의존해야 하는 느낌이었습니다.

## AI의 응답을 개선하기 위해 추가했던 여러 정보(context)는 무엇인가요?

### 1. TDD/RTL 방법론 가이드

**TDD 사이클** (`docs/references/TDD_GUIDE.md`)

- RED: 최소 실패 테스트, GREEN: 최소 구현, REFACTOR: 구조 개선 (동작 변경 금지)
- Kent Beck의 "Tidy First" 원칙: 구조적 변경과 동작 변경 분리
- 커밋 규율: 테스트+린트 통과 시에만, 구조/동작 별도 커밋

**Testing Library 철학** (`docs/references/RTL_GUIDE.md`)

- 구현 세부사항(className, 내부 상태) 의존 금지
- 쿼리 우선순위

### 2. 에이전트별 역할과 금지 사항

각 에이전트에게 해야 할 일과 하면 안 되는 일을 명시하여 역할 침범 방지

**RED (red-test-writer)**

- 해야: 실패 테스트 작성, 접근성 쿼리 사용, MSW 헬퍼 준비
- 금지: 구현 코드 수정, 여러 검증 우겨넣기, 비결정적 요소 방치

**GREEN (green-implementer)**

- 해야: 파라미터 사용한 최소 구현, 테스트 통과
- 금지: 하드코딩, 리팩토링, 과도한 추상화/최적화

**REFACTOR (refactor-engineer)**

- 해야: 한 번에 하나씩 리팩토링, 각 변경 후 테스트
- 금지: 동작 변경, 새 기능 추가, 여러 리팩토링 동시 수행

**ORCHESTRATOR (tdd-orchestrator)**

- 해야: RED-GREEN-REFACTOR 사이클 자동화, 게이트 조건 검증, 커밋 확인
- 금지: 게이트 조건 무시, 사이클 중단, 커밋 검증 생략

### 3. 자기 검증 체계

**작업 단계별 체크리스트**

- 작업 전: 필수 파일 확인, 전체 범위 파악
- 작업 중: output 문서 즉시 업데이트, 진행 상황 추적
- 작업 후: 린트 검사, UTF-8 인코딩 검증, 깃 커밋 생성

**Before/After 예시 제공**

- 좋은 예시: 접근성 쿼리, 파라미터 사용, 단일 리팩토링
- 안티패턴: handlersUtils 미확인, 하드코딩, 역할 침범

### 효과

"해도 되는 것"보다 "하면 안 되는 것"을 명시하니 AI가 보수적으로 행동하고, 특히 **파라미터 무시**, **역할 침범**, **체크리스트 무시** 같은 흔한 실수가 대폭 감소했습니다.

## 이 context를 잘 활용하게 하기 위해 했던 노력이 있나요?

1. 에이전트 실행 전, 맥락 점검 루틴 유도
   - 에이전트가 맥락을 스스로 점검하도록 유도
2. 체크리스트 기반의 컨텍스트 인식 확인
   - 각 에이전트에게 체크리스트 기반 자기 검증
   - 각 단계가 완료되었을 때마다 스스로 이 체크리스트를 통과하도록 설계
3. SPEC /RED / GREEN / REFACTOR 단계별 에이전트 분리 및 컨텍스트 최소화
   - 모든 내용을 한번에 맡기면 혼동하는 경우가 많았습니다. 이를 해결하기 위해 4단계의 독립된 에이전트로 분리했습니다.
   - 각 에이전트에게는 해당 단계에 필요한 컨텍스트만 전달했습니다.

## 생성된 여러 결과는 만족스러웠나요? AI의 응답을 어떤 기준을 갖고 '평가(evaluation)'했나요?

### 초기 문제: 역할 침범과 형식 오류

초기 결과물은 형식도 본질도 벗어났습니다. RED에서 구현까지 하고, GREEN에서 하드코딩만 하고, REFACTOR에서 새 기능을 추가하는 식이었습니다.

### 4단계 평가

**1단계: 역할별 체크리스트**

- **RED**: 구현 수정 안함, 의도적 실패 확인, 접근성 쿼리 사용
- **GREEN**: 파라미터 사용 구현 (하드코딩 금지), 리팩토링 안함, 테스트 통과
- **REFACTOR**: 동작 변경 안함, 한 번에 하나씩, 테스트 유지

**2단계: 자동화 게이트 조건** (tdd-orchestrator)

- **RED Gate**: Assertion 기반, [RED] 커밋 존재
- **GREEN Gate**: 전체 테스트 통과, 린트 통과, [GREEN] 커밋 존재
- **REFACTOR Gate**: 테스트 유지, 린트 통과, [REFACTOR] 커밋 존재

**3단계: 품질 규칙**

- 린트 검사 필수, UTF-8 인코딩 검증

**4단계: 3회 재시도 루프**

- 미통과 시: 원인 분석 → 재실행 → 구체적 지시 → 재실행 → 사용자 개입

## AI에게 어떻게 질문하는것이 더 나은 결과를 얻을 수 있었나요? 시도했던 여러 경험을 알려주세요.

처음엔 AI에게 “이걸 해줘” 식으로 단순히 명령했습니다. 하지만 결과물은 늘 어딘가 어색했고, 맥락을 제대로 반영하지 못했습니다. 그래서 저는 AI를 신입 개발자라고 생각하기로 했습니다. 막 입사한 신입에게 온보딩하듯, 프로젝트의 구조나 규칙, 작업 우선순위를 하나씩 설명하고 작업 전 반드시 확인해야 할 항목을 명확히 제시했습니다.

단순히 정보를 나열하는 게 아니라, 작업 전에 스스로 지금 단계가 무엇이고 어떤 제약이 있는지를 점검하도록 하자 결과가 달라졌습니다. 테스트 코드에서도 실제 프로젝트 구조를 반영하고, 기존 유틸을 활용하며, 의도에 맞게 사고하는 모습이 보이기 시작했습니다.

## AI에게 지시하는 작업의 범위를 어떻게 잡았나요? 범위를 좁게, 넓게 해보고 결과를 적어주세요. 그리고 내가 생각하는 적절한 단위를 말해보세요.

처음에는 작업 범위를 넓게 가져가 다음과 같이 작성했습니다. 기능 구현사항에 대한 모든 RED 케이스 작성이 완료되면 작성된 RED에 대한 GREEN 케이스 작성 그리고 GREEN이 모두 완료되면 REFACTOR 실행

이렇게 작업을 크게 가져가니 기능에 대한 명세도 이해를 못하고 코드도 누락되는 부분이 많고 뭔가 고장난 것처럼 이상한 결과를 만들어주어 다음과 같이 수정했습니다.

하나의 테스트 케이스 단위로 TDD 싸이클 수행. 작업 범위를 작게 여러번 가져가 문제가 생겼을 때 추적을 하기 쉽고 이전에 비해 잘못된 코드를 주는 경우가 많이 줄어들게 되었스빈다.

## 동기들에게 공유하고 싶은 좋은 참고자료나 문구가 있었나요? 마음껏 자랑해주세요.

정작 클로드코드를 사용하면서 앤트로픽 프롬프트 가이드를 읽지 않았습니다ㅜ

- https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices

## AI가 잘하는 것과 못하는 것에 대해 고민한 적이 있나요? 내가 생각하는 지점에 대해 작성해주세요.

잘하는 건 패턴화된 사고와 일관된 행동입니다. 명확한 규칙이나 절차가 주어졌을 때, AI는 사람보다 훨씬 빠르고 안정적으로 그 틀을 지켜냅니다. 특히 테스트 코드나 리팩터링처럼 기준이 뚜렷한 작업에서는, 실수를 거의 하지 않고 체계적으로 수행합니다. 또, 피드백을 주면 즉시 반영하고 개선된 형태로 반복할 수 있다는 점도 강점입니다.

반면 AI가 어려워하는 건 맥락 추론과 의도 이해입니다. 두루뭉술 하게 설명한 부분을 잘 잡지 못하고, 이전 대화에서 다뤘던 전제나 숨은 의도를 놓치는 경우가 많습니다. 특히 여러 기능이 서로 연결된 복합적인 작업에서는, 한 단계의 의도를 잘못 이해하면 이후의 결과가 전부 어긋나버리기도 했습니다.

AI는 명확한 규칙과 구체적 문맥 안에서 좋은 성과를 내지만 논리적으로 드러나지 않은 맥락은 잘 파악하지 못합니다.

## 마지막으로 느낀점에 대해 적어주세요!

AI에게 감성을 호소해봤자 저만 손해라는 걸 알게 되었
습니다.
